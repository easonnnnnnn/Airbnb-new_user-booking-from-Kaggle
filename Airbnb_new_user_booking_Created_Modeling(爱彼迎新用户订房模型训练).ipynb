{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginning:\n",
    "### 在参考kaggle 中 各路大神后，模型的搭建选择Xboosting 模型，并且参考了Sandro的参数，后采用NDCG的搜索引擎指标来对输出结果进行排序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 导入已经进行完特征工程的数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试集\n",
    "xtrain = pd.read_csv(\"Finish_train.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#验证集\n",
    "ytrain = pd.read_csv(\"Airbnb_ytrain_v2.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对验证集不连续的变量进行labelencoder，转换为数字："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AU', 'CA', 'DE', 'ES', 'FR', 'GB', 'IT', 'NDF', 'NL', 'PT', 'US',\n",
       "       'other'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#一共有几个不同的变量\n",
    "np.unique(ytrain.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "ytrain_le = le.fit_transform(ytrain.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  7, 10, ...,  7,  7,  7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分数据集："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里标注一下，我电脑最多能跑出百分之30的数据，再多数据的话报错：MemoryError,暂时还没有得到解决方案，可能是模型算法堆叠层次比较高——CPU i7-7700K,内存16G："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64035\n"
     ]
    }
   ],
   "source": [
    "n = int(xtrain.shape[0]*0.3)\n",
    "print (n)\n",
    "xtrain_new = xtrain.iloc[:n, :]\n",
    "ytrain_new = ytrain_le[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64035, 416)\n",
      "(64035,)\n"
     ]
    }
   ],
   "source": [
    "print (xtrain_new.shape)\n",
    "print (ytrain_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标注问题; 把float64换为32，仍然不行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_new = xtrain_new.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_new.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StandardScaling the dataset（把特征数据标准化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler()\n",
    "xtrain_new = X_scaler.fit_transform(xtrain_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.0714065 , -1.00916911,  0.37960279, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-4.0714065 , -0.44095995,  0.83230957, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-4.0714065 , -0.15685537, -0.75216418, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 1.57581638, -1.00916911, -0.97851757, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.57581638, -1.00916911, -0.97851757, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.57581638, -1.00916911, -0.97851757, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airbnb NDCG :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里参考Kaggle上的一个NDCG的包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Kaggle Kernels\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def dcg_score(y_true, y_score, k=5):\n",
    "    \n",
    "    \"\"\"\n",
    "    y_true : array, shape = [n_samples]\n",
    "        Ground truth (true relevance labels).\n",
    "    y_score : array, shape = [n_samples, n_classes]\n",
    "        Predicted scores.\n",
    "    k : int\n",
    "    \"\"\"\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    \n",
    "    \n",
    "    #order = [3,2,1,7]\n",
    "    #y_true = [0,1,0,0]\n",
    "    #y_true =[0,0,1,0]\n",
    "    \n",
    "    \n",
    "\n",
    "    gain = 2 ** y_true - 1\n",
    "\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "    # 0 doesn't count =>>>> only reduce 1 \n",
    "\n",
    "\n",
    "def ndcg_score(ground_truth, predictions, k=5):\n",
    "    \n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    ground_truth : array, shape = [n_samples]\n",
    "        Ground truth (true labels represended as integers).\n",
    "    predictions : array, shape = [n_samples, n_classes]\n",
    "        Predicted probabilities.\n",
    "    k : int\n",
    "        Rank.\n",
    "        \n",
    "    Example\n",
    "    -------\n",
    "    >>> ground_truth = [1, 0, 2]\n",
    "    >>> predictions = [[0.15, 0.55, 0.2], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\n",
    "    >>> score = ndcg_score(ground_truth, predictions, k=2)\n",
    "    1.0\n",
    "    >>> predictions = [[0.9, 0.5, 0.8], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\n",
    "    >>> score = ndcg_score(ground_truth, predictions, k=2)\n",
    "    0.6666666666\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(range(len(predictions) + 1))\n",
    "    T = lb.transform(ground_truth)\n",
    "    \n",
    "    #ground_truth = [1, 0, 2]  =>>>> \n",
    "    #ground_truth : [[0, 1, 0],       [1, 0, 0],    [0, 0, 1]]\n",
    "    #predictions: [[0.15, 0.55, 0.2], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\n",
    "    #zip =>>> take one vector from each batch\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    # Iterate over each y_true and compute the DCG score\n",
    "    for y_true, y_score in zip(T, predictions):\n",
    "        actual = dcg_score(y_true, y_score, k)\n",
    "        best = dcg_score(y_true, y_true, k)\n",
    "        score = float(actual) / float(best)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Kaggle Kernels\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def dcg_score(y_true, y_score, k=5):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gain = 2 ** y_true - 1\n",
    "\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "def ndcg_score(ground_truth, predictions, k=5):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(range(len(predictions) + 1))\n",
    "    T = lb.transform(ground_truth)\n",
    "    scores = []\n",
    "    for y_true, y_score in zip(T, predictions):\n",
    "        actual = dcg_score(y_true, y_score, k)\n",
    "        best = dcg_score(y_true, y_true, k)\n",
    "        score = float(actual) / float(best)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost 模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customized_eval(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    top = []\n",
    "    for i in range(preds.shape[0]):\n",
    "        top.append(np.argsort(preds[i])[::-1][:5])\n",
    "    mat = np.reshape(np.repeat(labels,np.shape(top)[1]) == np.array(top).ravel(),np.array(top).shape).astype(int)\n",
    "    score = np.mean(np.sum(mat/np.log2(np.arange(2, mat.shape[1] + 2)),axis = 1))\n",
    "    return 'ndcg5', score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.6, 'max_depth': 6, 'subsample': 0.8, 'eta': 0.3, 'seed': 2017, 'num_class': 12, 'objective': 'multi:softprob'}\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.1\n",
    "N_ESTIMATORS = 50\n",
    "RANDOM_STATE = 2017\n",
    "MAX_DEPTH = 9\n",
    "# xgboost parameters\n",
    "\n",
    "NUM_XGB = 200\n",
    "\n",
    "params = {}\n",
    "params['colsample_bytree'] = 0.6\n",
    "params['max_depth'] = 6\n",
    "params['subsample'] = 0.8\n",
    "params['eta'] = 0.3\n",
    "params['seed'] = RANDOM_STATE\n",
    "params['num_class'] = 12\n",
    "params['objective'] = 'multi:softprob'   # output the probability instead of class. \n",
    "\n",
    "print (params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42690, 416) (21345, 416)\n",
      "[0]\ttrain-merror:0.41206\ttest-merror:0.49702\ttrain-ndcg5:0.80630\ttest-ndcg5:0.75994\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.39103\ttest-merror:0.47032\ttrain-ndcg5:0.81643\ttest-ndcg5:0.77029\n",
      "Stopping. Best iteration:\n",
      "[0]\ttrain-merror:0.41206\ttest-merror:0.49702\ttrain-ndcg5:0.80630\ttest-ndcg5:0.75994\n",
      "\n",
      "(42690, 416) (21345, 416)\n",
      "[0]\ttrain-merror:0.43076\ttest-merror:0.42464\ttrain-ndcg5:0.79645\ttest-ndcg5:0.79448\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.40815\ttest-merror:0.41532\ttrain-ndcg5:0.80748\ttest-ndcg5:0.79843\n",
      "[6]\ttrain-merror:0.40574\ttest-merror:0.41406\ttrain-ndcg5:0.80934\ttest-ndcg5:0.79911\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-merror:0.42574\ttest-merror:0.43101\ttrain-ndcg5:0.79973\ttest-ndcg5:0.79260\n",
      "\n",
      "(42690, 416) (21345, 416)\n",
      "[0]\ttrain-merror:0.44289\ttest-merror:0.40426\ttrain-ndcg5:0.78703\ttest-ndcg5:0.80917\n",
      "Multiple eval metrics have been passed: 'test-ndcg5' will be used for early stopping.\n",
      "\n",
      "Will train until test-ndcg5 hasn't improved in 5 rounds.\n",
      "[3]\ttrain-merror:0.41942\ttest-merror:0.39021\ttrain-ndcg5:0.79897\ttest-ndcg5:0.81623\n",
      "[6]\ttrain-merror:0.40942\ttest-merror:0.38946\ttrain-ndcg5:0.80417\ttest-ndcg5:0.81663\n",
      "Stopping. Best iteration:\n",
      "[1]\ttrain-merror:0.43432\ttest-merror:0.40928\ttrain-ndcg5:0.79208\ttest-ndcg5:0.80769\n",
      "\n",
      "\n",
      "The training score is: 0.8107062329167345\n",
      "The cv score is: 0.7958705361109363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_score_iter = []\n",
    "cv_score_iter = []\n",
    "\n",
    "kf = KFold(n_splits = 3, random_state=RANDOM_STATE)\n",
    "\n",
    "k_ndcg = 5\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(xtrain_new, ytrain_new):\n",
    "\n",
    "    X_train, X_test = xtrain_new[train_index, :], xtrain_new[test_index, :]\n",
    "    y_train, y_test = ytrain_new[train_index], ytrain_new[test_index]\n",
    "\n",
    "    print (X_train.shape, X_test.shape)\n",
    "    \n",
    "    train_xgb = xgb.DMatrix(X_train, label= y_train)\n",
    "    test_xgb = xgb.DMatrix(X_test, label = y_test)\n",
    "    \n",
    "    watchlist = [ (train_xgb,'train'), (test_xgb, 'test') ]\n",
    "\n",
    "    bst = xgb.train(params, \n",
    "                     train_xgb,\n",
    "                     NUM_XGB,\n",
    "                     watchlist,\n",
    "                     feval = customized_eval,\n",
    "                     verbose_eval = 3,\n",
    "                     early_stopping_rounds = 5)\n",
    "    \n",
    "    \n",
    "    #bst = xgb.train( params, dtrain, num_round, evallist )\n",
    "\n",
    "    y_pred = np.array(bst.predict(test_xgb))\n",
    "    y_pred_train = np.array(bst.predict(train_xgb))\n",
    "    \n",
    "    # for binary classification: we used to use f1 score, precision, recall, auc score.\n",
    "    # here for Airbnb we use the ndcg evaluation. \n",
    "\n",
    "    train_ndcg_score = ndcg_score(y_train, y_pred_train , k = k_ndcg)\n",
    "    cv_ndcg_score = ndcg_score(y_test, y_pred, k=k_ndcg)\n",
    "\n",
    "    train_score_iter.append(train_ndcg_score)\n",
    "    cv_score_iter.append(cv_ndcg_score)\n",
    "\n",
    "train_score_xgb = np.mean(train_score_iter)\n",
    "cv_score_xgb = np.mean(cv_score_iter)\n",
    "\n",
    "print (\"\\nThe training score is: {}\".format(train_score_xgb))\n",
    "print (\"The cv score is: {}\\n\".format(cv_score_xgb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
